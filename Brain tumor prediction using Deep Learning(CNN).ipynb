{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209 images belonging to 2 classes.\n",
      "Found 44 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "236/236 [==============================] - 91s 384ms/step - loss: 0.3889 - accuracy: 0.8275 - val_loss: 0.5339 - val_accuracy: 0.8182\n",
      "Epoch 2/25\n",
      "236/236 [==============================] - 91s 384ms/step - loss: 0.1654 - accuracy: 0.9366 - val_loss: 0.7100 - val_accuracy: 0.8409\n",
      "Epoch 3/25\n",
      "236/236 [==============================] - 91s 385ms/step - loss: 0.0713 - accuracy: 0.9752 - val_loss: 0.9253 - val_accuracy: 0.7955\n",
      "Epoch 4/25\n",
      "236/236 [==============================] - 95s 401ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 1.1806 - val_accuracy: 0.6818\n",
      "Epoch 5/25\n",
      "236/236 [==============================] - 101s 427ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 1.0856 - val_accuracy: 0.7727\n",
      "Epoch 6/25\n",
      "236/236 [==============================] - 105s 446ms/step - loss: 0.0289 - accuracy: 0.9929 - val_loss: 1.0366 - val_accuracy: 0.8409\n",
      "Epoch 7/25\n",
      "236/236 [==============================] - 91s 384ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 1.4057 - val_accuracy: 0.7273\n",
      "Epoch 8/25\n",
      "236/236 [==============================] - 91s 386ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 1.4168 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "236/236 [==============================] - 90s 382ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.2645 - val_accuracy: 0.7273\n",
      "Epoch 10/25\n",
      "236/236 [==============================] - 91s 386ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.3724 - val_accuracy: 0.7955\n",
      "Epoch 11/25\n",
      "236/236 [==============================] - 105s 444ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 1.4746 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "236/236 [==============================] - 101s 427ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 1.4733 - val_accuracy: 0.7727\n",
      "Epoch 13/25\n",
      "236/236 [==============================] - 89s 375ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.7715 - val_accuracy: 0.7955\n",
      "Epoch 14/25\n",
      "236/236 [==============================] - 90s 380ms/step - loss: 8.5539e-04 - accuracy: 1.0000 - val_loss: 1.9490 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "236/236 [==============================] - 92s 389ms/step - loss: 5.3161e-04 - accuracy: 0.9999 - val_loss: 2.4155 - val_accuracy: 0.7500\n",
      "Epoch 16/25\n",
      "236/236 [==============================] - 97s 411ms/step - loss: 2.6584e-04 - accuracy: 1.0000 - val_loss: 2.1021 - val_accuracy: 0.7500\n",
      "Epoch 17/25\n",
      "236/236 [==============================] - 91s 385ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 2.0740 - val_accuracy: 0.7500\n",
      "Epoch 18/25\n",
      "236/236 [==============================] - 91s 387ms/step - loss: 0.0151 - accuracy: 0.9945 - val_loss: 2.3198 - val_accuracy: 0.7045\n",
      "Epoch 19/25\n",
      "236/236 [==============================] - 92s 392ms/step - loss: 0.0093 - accuracy: 0.9963 - val_loss: 1.7798 - val_accuracy: 0.7727\n",
      "Epoch 20/25\n",
      "236/236 [==============================] - 91s 386ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 1.8746 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "236/236 [==============================] - 90s 381ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 1.7627 - val_accuracy: 0.7955\n",
      "Epoch 22/25\n",
      "236/236 [==============================] - 97s 409ms/step - loss: 5.5967e-04 - accuracy: 1.0000 - val_loss: 1.5684 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "236/236 [==============================] - 92s 391ms/step - loss: 2.9071e-04 - accuracy: 1.0000 - val_loss: 1.5789 - val_accuracy: 0.7955\n",
      "Epoch 24/25\n",
      "236/236 [==============================] - 93s 393ms/step - loss: 1.6638e-04 - accuracy: 1.0000 - val_loss: 1.4809 - val_accuracy: 0.8409\n",
      "Epoch 25/25\n",
      "236/236 [==============================] - 95s 401ms/step - loss: 1.0079e-04 - accuracy: 1.0000 - val_loss: 1.9341 - val_accuracy: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b5eeaf1bc8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##This the Brain Tumor Prediction model Using Deep Learning(CNN)\n",
    "##There are Four Steps In doing this\n",
    "##First we have to build cnn and fit cnn to the images\n",
    "##This Model Is a Basic model with less no of images ot train\n",
    "##Step1 : Applying convolution to the layer by applying relu activation function.\n",
    "##Step2 : Then max pooling to it.\n",
    "##Step3 : Then by applying flattening to max pooling step to give them as input to neural network\n",
    "##Step4 : Then we canstruct a fully connected layer same as artificial neural network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "##BY adding second layer we get better accuracy\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "##To avoid Over Fitting\n",
    "classifier.add(Dropout(p = 0.2))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "##Setting Images to the CNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('brain_tumor_dataset/Training',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 50,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('brain_tumor_dataset/Testing',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 50,\n",
    "                                            class_mode = 'binary')\n",
    "##Fiting to the CNN\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 236,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 0, 'yes': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##To know which class is which label\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "##By this we can Predict the single I/p By taking the sample image\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('sample.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Yes'\n",
    "else:\n",
    "    prediction = 'No'\n",
    "print(prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
